https://semiconsam.substack.com/p/script-for-expert-call-nvidia-h20?r=4k4uta
Q: Is OpenAI's first-generation Titan ASIC design very similar to the TPU? Is this related to OpenAI recently renting more TPUs? A: From a technical perspective, it is reasonable that OpenAI's first-generation Titan ASIC design is similar to the TPU. The TPU was a successful first-generation ASIC design, and many subsequent ASICs have, to some extent, referenced its concepts. This architectural similarity is beneficial for the continuity of future models and can better adapt to existing and future model R&D needs. OpenAI's recent increase in renting TPUs may be related to its self-developed ASIC not being mature yet and requiring external computing power support in the short term. While there is no direct causal link, the architectural similarity provides a certain technical basis for adapting to rented TPUs.

QTCM -> Questions that come to mind

What is the state of this chip?

Is it available?

will it be the same playbook as google to not sell it but instead just renting it?

is there any information on the architecture of the chip?

how did these people know that its similar to the tpu from google?

why all of a sudden is openai making chips? is it never good to depend from nvidia/tsmc?

what are the other players doing? anthropic xai?

